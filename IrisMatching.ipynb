{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced features shape: (2268, 107)\n",
      "Unique labels in train_labels: ['001' '002' '003' '004' '005' '006' '007' '008' '009' '010' '011' '012'\n",
      " '013' '014' '015' '016' '017' '018' '019' '020' '021' '022' '023' '024'\n",
      " '025' '026' '027' '028' '029' '030' '031' '032' '033' '034' '035' '036'\n",
      " '037' '038' '039' '040' '041' '042' '043' '044' '045' '046' '047' '048'\n",
      " '049' '050' '051' '052' '053' '054' '055' '056' '057' '058' '059' '060'\n",
      " '061' '062' '063' '064' '065' '066' '067' '068' '069' '070' '071' '072'\n",
      " '073' '074' '075' '076' '077' '078' '079' '080' '081' '082' '083' '084'\n",
      " '085' '086' '087' '088' '089' '090' '091' '092' '093' '094' '095' '096'\n",
      " '097' '098' '099' '100' '101' '102' '103' '104' '105' '106' '107' '108']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'001': (107,), '002': (107,), '003': (107,), '004': (107,), '005': (107,)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Simulated data to illustrate the example\n",
    "# Suppose we have 108 unique classes and 2268 samples\n",
    "np.random.seed(0)\n",
    "num_samples = 2268\n",
    "num_features = 1536\n",
    "num_classes = 108\n",
    "\n",
    "# Randomly generate train_features with shape (2268, 1536)\n",
    "train_features = np.random.rand(num_samples, num_features)\n",
    "\n",
    "# Randomly generate train_labels with values from '001' to '108'\n",
    "train_labels = np.array([f\"{i:03}\" for i in np.random.randint(1, num_classes + 1, num_samples)])\n",
    "\n",
    "# Insttrain_features = np.vstack(train_features)antiate and fit LDA model\n",
    "lda = LinearDiscriminantAnalysis(n_components=min(num_classes - 1, num_features))\n",
    "\n",
    "# Perform LDA transformation\n",
    "reduced_features = lda.fit_transform(train_features, train_labels)\n",
    "print(\"Reduced features shape:\", reduced_features.shape)  # Should be (2268, 107)\n",
    "print(\"Unique labels in train_labels:\", np.unique(train_labels))\n",
    "\n",
    "# Compute class centers in the reduced space\n",
    "class_centers = {}\n",
    "for label in np.unique(train_labels):\n",
    "    # Select projected vectors (f) of the current class\n",
    "    class_reduced_features = reduced_features[train_labels == label]\n",
    "    \n",
    "    # Calculate the mean vector for this class in reduced space\n",
    "    class_centers[label] = np.mean(class_reduced_features, axis=0)\n",
    "\n",
    "# Outputting some results for illustration\n",
    "# Display the shape of the mean vector for the first few classes\n",
    "{label: center.shape for label, center in list(class_centers.items())[:5]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Sample feature vectors (2D array, where each row is a feature vector)\n",
    "features = np.array([\n",
    "    [1.0, 1.2],  # Class 0\n",
    "    [1.1, 1.3],  # Class 0\n",
    "    [5.0, 5.2],  # Class 1\n",
    "    [5.1, 5.3],  # Class 1\n",
    "    [9.0, 9.2],  # Class 2\n",
    "    [9.1, 9.3],  # Class 2\n",
    "])\n",
    "\n",
    "# Corresponding labels for each feature vector\n",
    "labels = np.array([0, 0, 1, 1, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Pairs (Feature Vector Pairs):\n",
      "Pair 1: (array([5. , 5.2]), array([5.1, 5.3])) | Genuine\n",
      "Pair 2: (array([1.1, 1.3]), array([1. , 1.2])) | Genuine\n",
      "Pair 3: (array([9.1, 9.3]), array([5.1, 5.3])) | Impostor\n",
      "Pair 4: (array([5. , 5.2]), array([1.1, 1.3])) | Impostor\n",
      "[(array([5. , 5.2]), array([5.1, 5.3])), (array([1.1, 1.3]), array([1. , 1.2])), (array([9.1, 9.3]), array([5.1, 5.3])), (array([5. , 5.2]), array([1.1, 1.3]))]\n",
      "[1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def create_pairs(features, labels, num_genuine_pairs=2, num_impostor_pairs=2):\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "    \n",
    "    # Dictionary to group features by their label\n",
    "    label_to_indices = {label: np.where(labels == label)[0] for label in np.unique(labels)}\n",
    "    \n",
    "    # Generate Genuine Pairs\n",
    "    for _ in range(num_genuine_pairs):\n",
    "        label = random.choice(list(label_to_indices.keys()))\n",
    "        i, j = np.random.choice(label_to_indices[label], 2, replace=False)\n",
    "        pairs.append((features[i], features[j]))\n",
    "        pair_labels.append(1)  # Label 1 for genuine pairs\n",
    "\n",
    "    # Generate Impostor Pairs\n",
    "    for _ in range(num_impostor_pairs):\n",
    "        label1, label2 = np.random.choice(list(label_to_indices.keys()), 2, replace=False)\n",
    "        i = np.random.choice(label_to_indices[label1])\n",
    "        j = np.random.choice(label_to_indices[label2])\n",
    "        pairs.append((features[i], features[j]))\n",
    "        pair_labels.append(0)  # Label 0 for impostor pairs\n",
    "\n",
    "    return pairs, pair_labels\n",
    "\n",
    "# Run the function\n",
    "genuine_impostor_pairs, pair_labels = create_pairs(features, labels, num_genuine_pairs=2, num_impostor_pairs=2)\n",
    "\n",
    "# Display results\n",
    "print(\"Generated Pairs (Feature Vector Pairs):\")\n",
    "for idx, (pair, label) in enumerate(zip(genuine_impostor_pairs, pair_labels)):\n",
    "    print(f\"Pair {idx+1}:\", pair, \"| Genuine\" if label == 1 else \"| Impostor\")\n",
    "\n",
    "print(genuine_impostor_pairs)\n",
    "print(pair_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
